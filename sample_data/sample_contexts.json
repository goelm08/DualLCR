{
  "A00-1004_P91-1022_0": {
    "citation_context": " encoding scheme transformation (for Chinese), sentence level segmentation, parallel text alignment, Chinese word segmentation (Nie et al., 1999) and English expression extraction. The parallel Web pages we collected from various sites are not all of the same quality. Some are highly parallel and easy to align while others can be very noisy. Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages. A number of alignment techniques have been proposed, varying from statistical methods (Brown et al., 1991; Gale and Church, 1991) to lexical methods (Kay and Roscheisen, 1993; Chen, 1993). The method we adopted is that of Simard et al. (1992). Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods. Cognates are identical sequences of characters in corresponding words in two languages. They are commonly found in English and French. In the case of English-Chinese alignment, where there are no cognates shared by the two languages, only the HTML markup in both texts are taken as cog",
    "ref_id": "P91-1022",
    "citing_id": "A00-1004",
    "masked_text": " encoding scheme transformation (for Chinese), sentence level segmentation, parallel text alignment, Chinese word segmentation (OTHERCIT) and English expression extraction. The parallel Web pages we collected from various sites are not all of the same quality. Some are highly parallel and easy to align while others can be very noisy. Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages. A number of alignment techniques have been proposed, varying from statistical methods ( TARGETCIT ; OTHERCIT) to lexical methods (OTHERCIT). The method we adopted is that of OTHERCIT. Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods. Cognates are identical sequences of characters in corresponding words in two languages. They are commonly found in English and French. In the case of English-Chinese alignment, where there are no cognates shared by the two languages, only the HTML markup in both texts are taken as cog",
    "preprocessed": [
      504339,
      1748,
      1124,
      1625,
      10,
      12,
      1681,
      9,
      3,
      6981,
      144,
      2805,
      3,
      1090,
      1875,
      3529,
      3,
      1681,
      2557,
      2805,
      10,
      504341,
      9,
      4,
      3108,
      96,
      1291,
      1,
      0,
      1090,
      1064,
      6923,
      24,
      758,
      21,
      276,
      537,
      22,
      30,
      63,
      2,
      0,
      281,
      255,
      1,
      148,
      22,
      474,
      1090,
      4,
      2615,
      7,
      14927,
      173,
      1477,
      43,
      26,
      326,
      6729,
      1,
      19667,
      3108,
      6,
      1681,
      1090,
      8264,
      13,
      2137,
      326,
      1134,
      308,
      2,
      0,
      1379,
      244,
      5,
      0,
      8138,
      606,
      4,
      5391,
      164,
      2,
      0,
      48,
      3292,
      1,
      8,
      146,
      2,
      3529,
      384,
      36,
      49,
      262,
      3,
      1826,
      21,
      948,
      81,
      10,
      504340,
      39,
      504341,
      9,
      7,
      7257,
      81,
      10,
      504341,
      9,
      1,
      0,
      107,
      24,
      3434,
      13,
      15,
      2,
      504341,
      1,
      308,
      40,
      5490,
      60,
      622,
      2085,
      4,
      504339,
      19,
      3529,
      792,
      3,
      0,
      107,
      13,
      61,
      1590,
      4,
      444,
      851,
      7,
      3677,
      11,
      1123,
      47,
      2506,
      622,
      6,
      55,
      81,
      1,
      88695,
      22,
      1900,
      845,
      2,
      5312,
      5,
      962,
      1726,
      5,
      48,
      3292,
      1,
      160,
      22,
      1305,
      106,
      5,
      3108,
      4,
      4659,
      1,
      5,
      0,
      150,
      2,
      3108,
      6,
      1681,
      3529,
      3,
      349,
      103,
      22,
      73,
      88695,
      2380,
      16,
      0,
      48,
      3292,
      3,
      111,
      0,
      21057,
      21710,
      5,
      60,
      8264,
      22,
      939,
      19,
      22464
    ],
    "tc_index": 101
  },
  "A00-1007_P97-1035_0": {
    "citation_context": "samples, the necessary sampling size, representativeness in corpus design and other have been discussed for quite some time (e.g. (Garside et al., 1997; Atkins et al., 1992; Crowdy, 1993; Biber, 1993)). Also the neighboring area of evaluation of NLP systems (for an overview, see Sparck Jones and Galliers (1996)) seems to have advanced further. Some work have been done in the area of natural language dialogue systems, e.g. on the design of Wizard of Oz-studies (Dahlback et al., 1998), on measures for inter-rater reliability (Carletta, 1996), on frameworks for evaluating spoken dialogue agents (Walker et al., 1998) and on the use of different corpora in the development of a particular system (The Carnegie-Mellon Communicator, Eskenazi et al. (1999)). The question we are addressing in this paper is how to collect and analyse relevant corpora. We begin by describing what we consider to be the main advantages and disadvantages of the two currently used methods; studies of human dialogues and Wizard of Oz-dialogues, especially focusing on the ecological validity of the methods. We then describe a method called 'distilling dialogues', which can serve as a supplement to the other two. 2 Natural and Wizard of ",
    "ref_id": "P97-1035",
    "citing_id": "A00-1007",
    "masked_text": "samples, the necessary sampling size, representativeness in corpus design and other have been discussed for quite some time (e.g. (OTHERCIT)). Also the neighboring area of evaluation of NLP systems (for an overview, see OTHERCIT) seems to have advanced further. Some work have been done in the area of natural language dialogue systems, e.g. on the design of Wizard of Oz-studies (OTHERCIT), on measures for inter-rater reliability (OTHERCIT), on frameworks for evaluating spoken dialogue agents ( TARGETCIT and on the use of different corpora in the development of a particular system (The Carnegie-Mellon Communicator, OTHERCIT). The question we are addressing in this paper is how to collect and analyse relevant corpora. We begin by describing what we consider to be the main advantages and disadvantages of the two currently used methods; studies of human dialogues and Wizard of Oz-dialogues, especially focusing on the ecological validity of the methods. We then describe a method called 'distilling dialogues', which can serve as a supplement to the other two. 2 Natural and Wizard of ",
    "preprocessed": [
      327,
      3,
      0,
      904,
      1632,
      347,
      3,
      34875,
      5,
      4007,
      200,
      4,
      76,
      36,
      49,
      597,
      12,
      2931,
      148,
      71,
      10,
      1029,
      10,
      504341,
      9,
      9,
      1,
      56,
      0,
      7256,
      371,
      2,
      331,
      2,
      15812,
      164,
      10,
      12,
      23,
      2553,
      3,
      1830,
      504341,
      9,
      1642,
      7,
      36,
      1008,
      232,
      1,
      148,
      258,
      36,
      49,
      1535,
      5,
      0,
      371,
      2,
      668,
      968,
      8349,
      164,
      3,
      1029,
      18,
      0,
      200,
      2,
      45727,
      2,
      28809,
      6,
      95,
      10,
      504341,
      9,
      3,
      18,
      621,
      12,
      2318,
      6,
      13253,
      1649,
      10,
      504341,
      9,
      3,
      18,
      6731,
      12,
      2124,
      9369,
      8349,
      635,
      10,
      504340,
      4,
      18,
      0,
      85,
      2,
      84,
      9535,
      5,
      0,
      136,
      2,
      8,
      612,
      72,
      10,
      0,
      35992,
      6,
      45600,
      58780,
      3,
      504341,
      9,
      1,
      0,
      1680,
      24,
      22,
      4690,
      5,
      20,
      130,
      13,
      296,
      7,
      6271,
      4,
      4342,
      975,
      9535,
      1,
      24,
      6191,
      16,
      3685,
      774,
      24,
      1324,
      7,
      26,
      0,
      478,
      1897,
      4,
      7240,
      2,
      0,
      48,
      1226,
      58,
      81,
      39,
      95,
      2,
      94,
      24857,
      4,
      45727,
      2,
      28809,
      6,
      24857,
      3,
      705,
      3289,
      18,
      0,
      3471,
      2131,
      2,
      0,
      81,
      1,
      24,
      332,
      685,
      8,
      107,
      1081,
      119,
      87783,
      24857,
      119,
      3,
      35,
      43,
      2289,
      19,
      8,
      6046,
      7,
      0,
      76,
      48,
      1,
      68,
      668,
      4,
      45727,
      2
    ],
    "tc_index": 97
  },
  "2009.06394_1507.07688_0": {
    "citation_context": "Extensive previous and ongoing work has been dedicated to estimating reward functions and interactive parameters (Albrecht, Crandall, and Ramamoorthy 2016;Albrecht and Stone 2019;Albrecht et al. 2020;Schwarting et al. 2019). In this work we presume that thereward matrix {(r mn1 , r mn2 )} 0<m\u2264M,0<n\u2264N , and altruism values \u03b1 1 , \u03b1 2 are known to both agents. Each agent can then, independently, construct the reward matrix {(r * mn1 , r * mn2 )} 0<m\u2264M,0<n\u2264N , which they will use to choose which intention to follow.",
    "ref_id": "1507.07688",
    "citing_id": "2009.06394",
    "masked_text": "Extensive previous and ongoing work has been dedicated to estimating reward functions and interactive parameters (OTHERCIT;OTHERCIT;OTHERCIT;OTHERCIT). In this work we presume that thereward matrix {(r mn1 , r mn2 )} 0<m\u2264M,0<n\u2264N , and altruism values \u03b1 1 , \u03b1 2 are known to both agents. Each agent can then, independently, construct the reward matrix {(r * mn1 , r * mn2 )} 0<m\u2264M,0<n\u2264N , which they will use to choose which intention to follow. TARGETCIT Extensive previous and ongoing work has been dedicated to estimating reward functions and interactive parameters (OTHERCIT;OTHERCIT;OTHERCIT;OTHERCIT). In this work we presume that thereward matrix {(r mn1 , r mn2 )} 0<m\u2264M,0<n\u2264N , and altruism values \u03b1 1 , \u03b1 2 are known to both agents. Each agent can then, independently, construct the reward matrix {(r * mn1 , r * mn2 )} 0<m\u2264M,0<n\u2264N , which they will use to choose which intention to follow.",
    "preprocessed": [
      1492,
      523,
      4,
      3060,
      258,
      45,
      49,
      5139,
      7,
      3528,
      5608,
      555,
      4,
      2957,
      372,
      10,
      504339,
      9,
      1,
      5,
      20,
      258,
      24,
      40643,
      15,
      504339,
      772,
      3998,
      10,
      268,
      89885,
      3,
      268,
      14695,
      9,
      3938,
      694,
      143,
      504339,
      143,
      504339,
      3,
      4,
      25917,
      314,
      4485,
      57,
      3,
      4485,
      68,
      22,
      306,
      7,
      60,
      635,
      1,
      155,
      918,
      43,
      332,
      3,
      1953,
      3,
      2351,
      0,
      5608,
      772,
      3998,
      10,
      268,
      1422,
      89885,
      3,
      268,
      1422,
      14695,
      9,
      3938,
      694,
      143,
      504339,
      143,
      504339,
      3,
      35,
      160,
      206,
      85,
      7,
      5433,
      35,
      5628,
      7,
      420,
      1,
      504340,
      1492,
      523,
      4,
      3060,
      258,
      45,
      49,
      5139,
      7,
      3528,
      5608,
      555,
      4,
      2957,
      372,
      10,
      504339,
      9,
      1,
      5,
      20,
      258,
      24,
      40643,
      15,
      504339,
      772,
      3998,
      10,
      268,
      89885,
      3,
      268,
      14695,
      9,
      3938,
      694,
      143,
      504339,
      143,
      504339,
      3,
      4,
      25917,
      314,
      4485,
      57,
      3,
      4485,
      68,
      22,
      306,
      7,
      60,
      635,
      1,
      155,
      918,
      43,
      332,
      3,
      1953,
      3,
      2351,
      0,
      5608,
      772,
      3998,
      10,
      268,
      1422,
      89885,
      3,
      268,
      1422,
      14695,
      9,
      3938,
      694,
      143,
      504339,
      143,
      504339,
      3,
      35,
      160,
      206,
      85,
      7,
      5433,
      35,
      5628,
      7,
      420,
      1
    ],
    "tc_index": 95
  },
  "2009.06394_1906.11064_0": {
    "citation_context": "Extensive previous and ongoing work has been dedicated to estimating reward functions and interactive parameters (Albrecht, Crandall, and Ramamoorthy 2016;Albrecht and Stone 2019;Albrecht et al. 2020;Schwarting et al. 2019). In this work we presume that the reward matrix {(r mn1 , r mn2 )} 0<m\u2264M,0<n\u2264N , and altruism values \u03b1 1 , \u03b1 2 are known to both agents. Each agent can then, independently, construct the reward matrix {(r * mn1 , r * mn2 )} 0<m\u2264M,0<n\u2264N , which they will use to choose which intention to follow.",
    "ref_id": "1906.11064",
    "citing_id": "2009.06394",
    "masked_text": "Extensive previous and ongoing work has been dedicated to estimating reward functions and interactive parameters (OTHERCIT;OTHERCIT;OTHERCIT;OTHERCIT). In this work we presume that the reward matrix {(r mn1 , r mn2 )} 0<m\u2264M,0<n\u2264N , and altruism values \u03b1 1 , \u03b1 2 are known to both agents. Each agent can then, independently, construct the reward matrix {(r * mn1 , r * mn2 )} 0<m\u2264M,0<n\u2264N , which they will use to choose which intention to follow. TARGETCIT Extensive previous and ongoing work has been dedicated to estimating reward functions and interactive parameters (OTHERCIT;OTHERCIT;OTHERCIT;OTHERCIT). In this work we presume that the reward matrix {(r mn1 , r mn2 )} 0<m\u2264M,0<n\u2264N , and altruism values \u03b1 1 , \u03b1 2 are known to both agents. Each agent can then, independently, construct the reward matrix {(r * mn1 , r * mn2 )} 0<m\u2264M,0<n\u2264N , which they will use to choose which intention to follow.",
    "preprocessed": [
      1492,
      523,
      4,
      3060,
      258,
      45,
      49,
      5139,
      7,
      3528,
      5608,
      555,
      4,
      2957,
      372,
      10,
      504339,
      9,
      1,
      5,
      20,
      258,
      24,
      40643,
      15,
      0,
      5608,
      772,
      3998,
      10,
      268,
      89885,
      3,
      268,
      14695,
      9,
      3938,
      694,
      143,
      504339,
      143,
      504339,
      3,
      4,
      25917,
      314,
      4485,
      57,
      3,
      4485,
      68,
      22,
      306,
      7,
      60,
      635,
      1,
      155,
      918,
      43,
      332,
      3,
      1953,
      3,
      2351,
      0,
      5608,
      772,
      3998,
      10,
      268,
      1422,
      89885,
      3,
      268,
      1422,
      14695,
      9,
      3938,
      694,
      143,
      504339,
      143,
      504339,
      3,
      35,
      160,
      206,
      85,
      7,
      5433,
      35,
      5628,
      7,
      420,
      1,
      504340,
      1492,
      523,
      4,
      3060,
      258,
      45,
      49,
      5139,
      7,
      3528,
      5608,
      555,
      4,
      2957,
      372,
      10,
      504339,
      9,
      1,
      5,
      20,
      258,
      24,
      40643,
      15,
      0,
      5608,
      772,
      3998,
      10,
      268,
      89885,
      3,
      268,
      14695,
      9,
      3938,
      694,
      143,
      504339,
      143,
      504339,
      3,
      4,
      25917,
      314,
      4485,
      57,
      3,
      4485,
      68,
      22,
      306,
      7,
      60,
      635,
      1,
      155,
      918,
      43,
      332,
      3,
      1953,
      3,
      2351,
      0,
      5608,
      772,
      3998,
      10,
      268,
      1422,
      89885,
      3,
      268,
      1422,
      14695,
      9,
      3938,
      694,
      143,
      504339,
      143,
      504339,
      3,
      35,
      160,
      206,
      85,
      7,
      5433,
      35,
      5628,
      7,
      420,
      1
    ],
    "tc_index": 96
  },
  "2009.06394_1510.07313_0": {
    "citation_context": "A wealth of previous research on autonomous driving has employed overly simplistic models of how other agents will behave, such as assuming constant velocity (Eiras et al. 2020;Sadigh and Kapoor 2015;Bender et al. 2015) or that vehicles only execute a small number of fixed trajectories for a given type of manoeuvre (Hermes et al. 2009;Ward et al. 2017). These assumptions lead to unexpected and undesirable behaviour, like failing to merge onto a highway or change lanes because the autonomous vehicle (AV) is not capable of anticipating that starting such a manoeuvre will result in the human drivers making space for the AV to finish completing the manoeuvre. The emerging field of interactive planning and decision-making for autonomous driving aims to address these problems by building interactive models that allow an AV to influence the actions taken by human drivers (Sadigh et al. 2016(Sadigh et al. , 2018)). For example, the scenario presented in Figure 1a; the AV (orange) is approaching a parked fire truck with a vehicle (purple) occupying the adjacent lane. Operating under the assumption that the purple car will continue to move at a constant velocity, the AV has no choice but to slow down and wait until the right lane is empty in order to continue. In contrast, an AV that is capable of anticipating how an interactive driver would respond to its actions might decide on a different course of action. For example, Sadigh et al. (2018) demonstrate an interactive planner that enables the AV to begin accelerating in order to determine whether the purple car will slow down to allow it It is common in recent work to on autonomous driving to develop hierarchical systems, where a discrete decisionmaker decides on intents or approximate trajectories for the AV, and a lower level motion planning system chooses continuous actions that realise these decisions (Fisac et al. 2019;Albrecht et al. 2020;Eiras et al. 2020;Cunningham et al. 2015). Incorporating models of interaction based on Stackelberg games into AV planning and decision-making systems has become a popular way of improving upon the na\u00efve models used by older systems that do not attempt to account for the interactive behaviour of other drivers. However, while solving Stackelberg games is computationally easier than alternative game theoretic formulations, the solution method presumes that players (i.e., the AV and other driver) take the role of either leader of follower, with the leader selecting their action first and the follower selecting their best response. In practice, without a means of direct communication and agreed upon protocol, it is impractical for two vehicles to dynamically allocate the roles of leader and follower. Given that the roles of leader and follower are ambiguous, the assumptions required for a Stackelberg game do not always hold in autonomous driving scenarios. This begs the question: will the violated assumptions result in undesirable behaviour?",
    "ref_id": "1510.07313",
    "citing_id": "2009.06394",
    "masked_text": "A wealth of previous research on autonomous driving has employed overly simplistic models of how other agents will behave, such as assuming constant velocity (OTHERCIT;OTHERCIT;OTHERCIT) or that vehicles only execute a small number of fixed trajectories for a given type of manoeuvre (OTHERCIT;OTHERCIT). These assumptions lead to unexpected and undesirable behaviour, like failing to merge onto a highway or change lanes because the autonomous vehicle (AV) is not capable of anticipating that starting such a manoeuvre will result in the human driv TARGETCIT that players (i.e., the AV and other driver) take the role of either leader of follower, with the leader selecting their action first and the follower selecting their best response. In practice, without a means of direct communication and agreed upon protocol, it is impractical for two vehicles to dynamically allocate the roles of leader and follower. Given that the roles of leader and follower are ambiguous, the assumptions required for a Stackelberg game do not always hold in autonomous driving scenarios. This begs the question: will the violated assumptions result in undesirable behaviour?",
    "preprocessed": [
      8,
      9098,
      2,
      523,
      170,
      18,
      4218,
      3250,
      45,
      1498,
      22605,
      27438,
      229,
      2,
      296,
      76,
      635,
      206,
      9944,
      3,
      92,
      19,
      5404,
      1151,
      1562,
      10,
      504339,
      9,
      27,
      15,
      4574,
      111,
      11264,
      8,
      236,
      146,
      2,
      1430,
      5402,
      12,
      8,
      369,
      127,
      2,
      28641,
      10,
      504339,
      9,
      1,
      31,
      3900,
      743,
      7,
      5220,
      4,
      10848,
      1579,
      3,
      341,
      9223,
      7,
      15300,
      3009,
      8,
      14725,
      27,
      358,
      29882,
      308,
      0,
      4218,
      2110,
      10,
      7798,
      9,
      13,
      30,
      1880,
      2,
      27693,
      15,
      2536,
      92,
      8,
      28641,
      206,
      376,
      5,
      0,
      94,
      436817,
      504340,
      15,
      4586,
      10,
      854,
      3,
      0,
      7798,
      4,
      76,
      6023,
      9,
      1662,
      0,
      147,
      2,
      343,
      8418,
      2,
      26939,
      3,
      11,
      0,
      8418,
      4944,
      54,
      593,
      121,
      4,
      0,
      26939,
      4944,
      54,
      763,
      137,
      1,
      5,
      604,
      3,
      185,
      8,
      766,
      2,
      590,
      809,
      4,
      6269,
      816,
      1034,
      3,
      40,
      13,
      18480,
      12,
      48,
      4574,
      7,
      5276,
      15800,
      0,
      1472,
      2,
      8418,
      4,
      26939,
      1,
      369,
      15,
      0,
      1472,
      2,
      8418,
      4,
      26939,
      22,
      9467,
      3,
      0,
      3900,
      447,
      12,
      8,
      45023,
      2906,
      491,
      30,
      1899,
      5083,
      5,
      4218,
      3250,
      3097,
      1,
      20,
      76670,
      0,
      1680,
      29,
      206,
      0,
      21338,
      3900,
      376,
      5,
      10848,
      1579,
      406
    ],
    "tc_index": 91
  },
  "1908.03586_1709.00043_0": {
    "citation_context": "In this paper we are interested in the construction of planar straight-line drawings with small edge-length ratio. From an algorithmic point of view, it has long been known that deciding whether a graph admits a planar straight-line drawing with edge-length ratio equal to 1 is an NP-hard problem. This was first proved by Eades and Wormald [6] for biconnected planar graphs and then by Cabello et al. [2] for triconnected planar graphs. From a combinatorial point of view, the study of planar straight-line drawings with small edge-length ratio started only recently, when Lazard, Lenhart, and Liotta [10] proved that every outerplanar graph admits a planar straight-line drawing with edge-length ratio smaller than 2 and that, for every fixed > 0, there exist outerplanar graphs whose every planar straight-line drawing has edge-length ratio larger than 2 \u2212 .",
    "ref_id": "1709.00043",
    "citing_id": "1908.03586",
    "masked_text": "In this paper we are interested in the construction of planar straight-line drawings with small edge-length ratio. From an algorithmic point of view, it has long been known that deciding whether a graph admits a planar straight-line drawing with edge-length ratio equal to 1 is an NP-hard problem. This was first proved by Eades and Wormald [6] for biconnected planar graphs and then by Cabello et al. [2] for triconnected planar graphs. From a combinatorial point of view, the study of planar straight-line drawings with small edge-length ratio started only recently, when Lazard, Lenhart, and Liott TARGETCIT io equal to 1 is an NP-hard problem. This was first proved by Eades and Wormald [6] for biconnected planar graphs and then by Cabello et al. [2] for triconnected planar graphs. From a combinatorial point of view, the study of planar straight-line drawings with small edge-length ratio started only recently, when Lazard, Lenhart, and Liotta [10] proved that every outerplanar graph admits a planar straight-line drawing with edge-length ratio smaller than 2 and that, for every fixed > 0, there exist outerplanar graphs whose every planar straight-line drawing has edge-length ratio larger than 2 \u2212 .",
    "preprocessed": [
      5,
      20,
      130,
      24,
      22,
      5246,
      5,
      0,
      1977,
      2,
      4297,
      7219,
      6,
      550,
      15086,
      11,
      236,
      2499,
      6,
      622,
      394,
      1,
      21,
      23,
      9756,
      567,
      2,
      1186,
      3,
      40,
      45,
      227,
      49,
      306,
      15,
      11074,
      354,
      8,
      1898,
      18093,
      8,
      4297,
      7219,
      6,
      550,
      6684,
      11,
      2499,
      6,
      622,
      394,
      1927,
      7,
      57,
      13,
      23,
      4030,
      6,
      2608,
      294,
      1,
      20,
      14,
      121,
      2025,
      16,
      382515,
      4,
      239393,
      41,
      222,
      46,
      12,
      109996,
      4297,
      3016,
      4,
      332,
      16,
      274935,
      513,
      655,
      1,
      41,
      68,
      46,
      12,
      217936,
      4297,
      3016,
      1,
      21,
      8,
      6064,
      567,
      2,
      1186,
      3,
      0,
      33,
      2,
      4297,
      7219,
      6,
      550,
      15086,
      11,
      236,
      2499,
      6,
      622,
      394,
      3364,
      111,
      669,
      3,
      104,
      295275,
      3,
      216966,
      3,
      4,
      504339,
      504340,
      11968,
      1927,
      7,
      57,
      13,
      23,
      4030,
      6,
      2608,
      294,
      1,
      20,
      14,
      121,
      2025,
      16,
      382515,
      4,
      239393,
      41,
      222,
      46,
      12,
      109996,
      4297,
      3016,
      4,
      332,
      16,
      274935,
      513,
      655,
      1,
      41,
      68,
      46,
      12,
      217936,
      4297,
      3016,
      1,
      21,
      8,
      6064,
      567,
      2,
      1186,
      3,
      0,
      33,
      2,
      4297,
      7219,
      6,
      550,
      15086,
      11,
      236,
      2499,
      6,
      622,
      394,
      3364,
      111,
      669,
      3,
      104,
      295275,
      3,
      216966,
      3,
      4,
      240234,
      41,
      190,
      46,
      2025,
      15,
      1255,
      76853,
      1898,
      18093,
      8,
      4297,
      7219,
      6,
      550,
      6684,
      11,
      2499,
      6,
      622,
      394,
      1604,
      47,
      68,
      4,
      15,
      3,
      12,
      1255,
      1430,
      277,
      694,
      3,
      103,
      2020,
      76853,
      3016,
      1392,
      1255,
      4297,
      7219,
      6,
      550,
      6684,
      45,
      2499,
      6,
      622,
      394,
      1076,
      47,
      68,
      3309,
      1
    ],
    "tc_index": 123
  },
  "1908.03586_1709.00043_1": {
    "citation_context": "Adopting the notation and the definitions from [9,10], we denote by \u03c1(\u0393 ) the edge-length ratio of a straight-line drawing \u0393 of a graph G, i.e., \u03c1(\u0393 ) = max e1,e2\u2208E(G)",
    "ref_id": "1709.00043",
    "citing_id": "1908.03586",
    "masked_text": "Adopting the notation and the definitions from [9,10], we denote by \u03c1(\u0393 ) the edge-length ratio of a straight-line drawing \u0393 of a graph G, i.e., \u03c1(\u0393 ) = max e1,e2\u2208E(G) TARGETCIT Adopting the notation and the definitions from [9,10], we denote by \u03c1(\u0393 ) the edge-length ratio of a straight-line drawing \u0393 of a graph G, i.e., \u03c1(\u0393 ) = max e1,e2\u2208E(G)",
    "preprocessed": [
      8701,
      0,
      11766,
      4,
      0,
      5015,
      21,
      41,
      40743,
      46,
      3,
      24,
      10497,
      16,
      504339,
      9,
      0,
      2499,
      6,
      622,
      394,
      2,
      8,
      7219,
      6,
      550,
      6684,
      6810,
      2,
      8,
      1898,
      280,
      3,
      854,
      3,
      504339,
      9,
      59,
      5055,
      504339,
      9,
      504340,
      8701,
      0,
      11766,
      4,
      0,
      5015,
      21,
      41,
      40743,
      46,
      3,
      24,
      10497,
      16,
      504339,
      9,
      0,
      2499,
      6,
      622,
      394,
      2,
      8,
      7219,
      6,
      550,
      6684,
      6810,
      2,
      8,
      1898,
      280,
      3,
      854,
      3,
      504339,
      9,
      59,
      5055,
      504339,
      9
    ],
    "tc_index": 41
  },
  "1908.03586_1709.00043_3": {
    "citation_context": "Several problems remain open; we mention some of them. First, what is the asymptotic behavior of the planar edge-length ratio of 2-trees? In particular, we wonder whether our geometric construction can lead to a better upper bound if coupled with a decomposition technique better than the one in Lemma 5. Second, is the planar edge-length ratio of cubic planar graphs sub-linear? The proof of Theorem 1 shows that this question has a negative answer when extended to all bounded-degree planar graphs. Finally, is the planar edge-length ratio of kouterplanar graphs bounded by some function of k? The results from [10] show that this is indeed the case for k = 1.",
    "ref_id": "1709.00043",
    "citing_id": "1908.03586",
    "masked_text": "Several problems remain open; we mention some of them. First, what is the asymptotic behavior of the planar edge-length ratio of 2-trees? In particular, we wonder whether our geometric construction can lead to a better upper bound if coupled with a decomposition technique better than the one in Lemma 5. Second, is the planar edge-length ratio of cubic planar graphs sub-linear? The proof of Theorem 1 shows that this question has a negative answer when extended to all bounded-degree planar graphs. Finally, is the planar edge-length ratio of kouterplanar graphs bounded by some function of k? The TARGETCIT what is the asymptotic behavior of the planar edge-length ratio of 2-trees? In particular, we wonder whether our geometric construction can lead to a better upper bound if coupled with a decomposition technique better than the one in Lemma 5. Second, is the planar edge-length ratio of cubic planar graphs sub-linear? The proof of Theorem 1 shows that this question has a negative answer when extended to all bounded-degree planar graphs. Finally, is the planar edge-length ratio of kouterplanar graphs bounded by some function of k? The results from [10] show that this is indeed the case for k = 1.",
    "preprocessed": [
      225,
      422,
      1648,
      704,
      39,
      24,
      11862,
      148,
      2,
      504,
      1,
      121,
      3,
      774,
      13,
      0,
      5626,
      493,
      2,
      0,
      4297,
      2499,
      6,
      622,
      394,
      2,
      256000,
      406,
      5,
      612,
      3,
      24,
      26131,
      354,
      82,
      3290,
      1977,
      43,
      743,
      7,
      8,
      444,
      1137,
      1148,
      283,
      1560,
      11,
      8,
      3167,
      344,
      444,
      47,
      0,
      69,
      5,
      15937,
      175,
      1,
      389,
      3,
      13,
      0,
      4297,
      2499,
      6,
      622,
      394,
      2,
      8352,
      4297,
      3016,
      1755,
      6,
      584,
      406,
      0,
      3138,
      2,
      3793,
      57,
      875,
      15,
      20,
      1680,
      45,
      8,
      399,
      4169,
      104,
      1374,
      7,
      63,
      5141,
      6,
      761,
      4297,
      3016,
      1,
      921,
      3,
      13,
      0,
      4297,
      2499,
      6,
      622,
      394,
      2,
      504339,
      3016,
      5141,
      16,
      148,
      145,
      2,
      563,
      406,
      0,
      504340,
      774,
      13,
      0,
      5626,
      493,
      2,
      0,
      4297,
      2499,
      6,
      622,
      394,
      2,
      256000,
      406,
      5,
      612,
      3,
      24,
      26131,
      354,
      82,
      3290,
      1977,
      43,
      743,
      7,
      8,
      444,
      1137,
      1148,
      283,
      1560,
      11,
      8,
      3167,
      344,
      444,
      47,
      0,
      69,
      5,
      15937,
      175,
      1,
      389,
      3,
      13,
      0,
      4297,
      2499,
      6,
      622,
      394,
      2,
      8352,
      4297,
      3016,
      1755,
      6,
      584,
      406,
      0,
      3138,
      2,
      3793,
      57,
      875,
      15,
      20,
      1680,
      45,
      8,
      399,
      4169,
      104,
      1374,
      7,
      63,
      5141,
      6,
      761,
      4297,
      3016,
      1,
      921,
      3,
      13,
      0,
      4297,
      2499,
      6,
      622,
      394,
      2,
      504339,
      3016,
      5141,
      16,
      148,
      145,
      2,
      563,
      406,
      0,
      34,
      21,
      41,
      190,
      46,
      174,
      15,
      20,
      13,
      3080,
      0,
      150,
      12,
      563,
      59,
      57,
      1
    ],
    "tc_index": 118
  },
  "2103.04556_1606.00931_0": {
    "citation_context": "Cox regression was first proposed in Cox (1972), which is a semi-parametric method focusing on estimating the hazard function. Among all its extensions, Akritas et al. (1995) first proposed using a one-hidden layer perceptron to replace the linear predictor of the coefficient. However, it generally failed mainly due to the low expressivity of the one-hidden layer perceptron (Xiang et al., 2000;Sargent, 2001). Therefore, Katzman et al. (2018) proposed to use the multi-layer perceptron instead of the one-layer perceptron (DeepSurv). Furthermore, (Kvamme et al., 2019) generalize the idea to the non-proportional hazard settings. In this paper, we unify their names as Cox-MLP when the context is clear. However, this line of work lacks a theoretical guarantee. This paper tries to fill this blank and propose the first guaranteed coverage of the survival time.",
    "ref_id": "1606.00931",
    "citing_id": "2103.04556",
    "masked_text": "Cox regression was first proposed in OTHERCIT, which is a semi-parametric method focusing on estimating the hazard function. Among all its extensions, OTHERCIT first proposed using a one-hidden layer perceptron to replace the linear predictor of the coefficient. However, it generally failed mainly due to the low expressivity of the one-hidden layer perceptron (OTHERCIT;OTHERCIT). Therefore, OTHERCIT proposed to use the multi-layer perceptron instead of the one-layer perceptron (DeepSurv). Furthermore, (OTHERCIT) generalize the idea to the n TARGETCIT coefficient. However, it generally failed mainly due to the low expressivity of the one-hidden layer perceptron (OTHERCIT;OTHERCIT). Therefore, OTHERCIT proposed to use the multi-layer perceptron instead of the one-layer perceptron (DeepSurv). Furthermore, (OTHERCIT) generalize the idea to the non-proportional hazard settings. In this paper, we unify their names as Cox-MLP when the context is clear. However, this line of work lacks a theoretical guarantee. This paper tries to fill this blank and propose the first guaranteed coverage of the survival time.",
    "preprocessed": [
      3959,
      756,
      14,
      121,
      262,
      5,
      504341,
      3,
      35,
      13,
      8,
      2548,
      6,
      4806,
      107,
      3289,
      18,
      3528,
      0,
      3118,
      145,
      1,
      154,
      63,
      78,
      6054,
      3,
      504341,
      121,
      262,
      42,
      8,
      69,
      6,
      4733,
      1003,
      19414,
      7,
      6264,
      0,
      584,
      2790,
      2,
      0,
      2074,
      1,
      108,
      3,
      40,
      1223,
      1955,
      1078,
      202,
      7,
      0,
      124,
      28095,
      2,
      0,
      69,
      6,
      4733,
      1003,
      19414,
      10,
      504339,
      9,
      1,
      418,
      3,
      504341,
      262,
      7,
      85,
      0,
      725,
      6,
      1003,
      19414,
      2138,
      2,
      0,
      69,
      6,
      1003,
      19414,
      10,
      504339,
      9,
      1,
      657,
      3,
      10,
      504341,
      9,
      10072,
      0,
      2842,
      7,
      0,
      98,
      504340,
      2074,
      1,
      108,
      3,
      40,
      1223,
      1955,
      1078,
      202,
      7,
      0,
      124,
      28095,
      2,
      0,
      69,
      6,
      4733,
      1003,
      19414,
      10,
      504339,
      9,
      1,
      418,
      3,
      504341,
      262,
      7,
      85,
      0,
      725,
      6,
      1003,
      19414,
      2138,
      2,
      0,
      69,
      6,
      1003,
      19414,
      10,
      504339,
      9,
      1,
      657,
      3,
      10,
      504341,
      9,
      10072,
      0,
      2842,
      7,
      0,
      132,
      6,
      3346,
      3118,
      2247,
      1,
      5,
      20,
      130,
      3,
      24,
      28036,
      54,
      7454,
      19,
      3959,
      6,
      19004,
      104,
      0,
      840,
      13,
      1343,
      1,
      108,
      3,
      20,
      550,
      2,
      258,
      7925,
      8,
      1361,
      6574,
      1,
      20,
      130,
      13013,
      7,
      8173,
      20,
      14299,
      4,
      790,
      0,
      121,
      9438,
      2420,
      2,
      0,
      336,
      71,
      1
    ],
    "tc_index": 101
  },
  "2103.04556_1606.00931_1": {
    "citation_context": "Algorithms. We choose the linear Cox regression (labeled as Cox Reg.) as a baseline. Besides, we conduct CoxPH (Katzman et al., 2018) and CoxCC (Kvamme et al., 2019) (both belong to Cox-MLP) using S(t) to return confidence band although they do not contain a theoretical guarantee.",
    "ref_id": "1606.00931",
    "citing_id": "2103.04556",
    "masked_text": "Algorithms. We choose the linear Cox regression (labeled as Cox Reg.) as a baseline. Besides, we conduct CoxPH (OTHERCIT) and CoxCC (OTHERCIT) (both belong to Cox-MLP) using S(t) to return confidence band although they do not contain a theoretical guarantee. TARGETCIT Algorithms. We choose the linear Cox regression (labeled as Cox Reg.) as a baseline. Besides, we conduct CoxPH (OTHERCIT) and CoxCC (OTHERCIT) (both belong to Cox-MLP) using S(t) to return confidence band although they do not contain a theoretical guarantee.",
    "preprocessed": [
      815,
      1,
      24,
      5433,
      0,
      584,
      3959,
      756,
      10,
      1828,
      19,
      3959,
      22698,
      1,
      9,
      19,
      8,
      799,
      1,
      3769,
      3,
      24,
      4631,
      504339,
      10,
      504341,
      9,
      4,
      504339,
      10,
      504341,
      9,
      10,
      60,
      6345,
      7,
      3959,
      6,
      19004,
      9,
      42,
      62583,
      9,
      7,
      3140,
      1252,
      1669,
      259,
      160,
      491,
      30,
      1844,
      8,
      1361,
      6574,
      1,
      504340,
      815,
      1,
      24,
      5433,
      0,
      584,
      3959,
      756,
      10,
      1828,
      19,
      3959,
      22698,
      1,
      9,
      19,
      8,
      799,
      1,
      3769,
      3,
      24,
      4631,
      504339,
      10,
      504341,
      9,
      4,
      504339,
      10,
      504341,
      9,
      10,
      60,
      6345,
      7,
      3959,
      6,
      19004,
      9,
      42,
      62583,
      9,
      7,
      3140,
      1252,
      1669,
      259,
      160,
      491,
      30,
      1844,
      8,
      1361,
      6574,
      1
    ],
    "tc_index": 56
  },
  "2103.04556_1606.00931_2": {
    "citation_context": "Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much",
    "ref_id": "1606.00931",
    "citing_id": "2103.04556",
    "masked_text": "Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much TARGETCIT Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much",
    "preprocessed": [
      461,
      18,
      3027,
      4,
      27411,
      229,
      22,
      307,
      5,
      3058,
      480,
      1,
      183,
      2,
      27411,
      229,
      22,
      701,
      504340,
      461,
      18,
      3027,
      4,
      27411,
      229,
      22,
      307,
      5,
      3058,
      480,
      1,
      183,
      2,
      27411,
      229,
      22,
      701
    ],
    "tc_index": 18
  },
  "2103.04556_1606.00931_3": {
    "citation_context": "Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much",
    "ref_id": "1606.00931",
    "citing_id": "2103.04556",
    "masked_text": "Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much TARGETCIT Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much",
    "preprocessed": [
      461,
      18,
      3027,
      4,
      27411,
      229,
      22,
      307,
      5,
      3058,
      480,
      1,
      183,
      2,
      27411,
      229,
      22,
      701,
      504340,
      461,
      18,
      3027,
      4,
      27411,
      229,
      22,
      307,
      5,
      3058,
      480,
      1,
      183,
      2,
      27411,
      229,
      22,
      701
    ],
    "tc_index": 18
  },
  "2103.04556_1606.00931_4": {
    "citation_context": "Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much",
    "ref_id": "1606.00931",
    "citing_id": "2103.04556",
    "masked_text": "Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much TARGETCIT Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much",
    "preprocessed": [
      461,
      18,
      3027,
      4,
      27411,
      229,
      22,
      307,
      5,
      3058,
      480,
      1,
      183,
      2,
      27411,
      229,
      22,
      701,
      504340,
      461,
      18,
      3027,
      4,
      27411,
      229,
      22,
      307,
      5,
      3058,
      480,
      1,
      183,
      2,
      27411,
      229,
      22,
      701
    ],
    "tc_index": 18
  },
  "2103.04556_1907.00825_0": {
    "citation_context": "It is challenging to deal with censored data, where we only have access to the incomplete information of survival time instead of its exact value. Fortunately, under linear predictor assumption, people can obtain guaranteed coverage for the confidence band of survival time using methods like Cox Regression. However, when relaxing the linear assumption with neural networks (e.g., Cox-MLP (Katzman et al., 2018;Kvamme et al., 2019)), we lose the guaranteed coverage. To recover the guaranteed coverage without linear assumption, we propose two algorithms based on conformal inference. In the first algorithm WCCI, we revisit weighted conformal inference and introduce a new non-conformity score based on partial likelihood. We then propose a two-stage algorithm T-SCI, where we run WCCI in the first stage and apply quantile conformal inference to calibrate the results in the second stage. Theoretical analysis shows that T-SCI returns guaranteed coverage under milder assumptions than WCCI. We conduct extensive experiments on synthetic data and real data using different methods, which validate our analysis.",
    "ref_id": "1907.00825",
    "citing_id": "2103.04556",
    "masked_text": "It is challenging to deal with censored data, where we only have access to the incomplete information of survival time instead of its exact value. Fortunately, under linear predictor assumption, people can obtain guaranteed coverage for the confidence band of survival time using methods like Cox Regression. However, when relaxing the linear assumption with neural networks (e.g., Cox-MLP (OTHERCIT;OTHERCIT)), we lose the guaranteed coverage. To recover the guaranteed coverage without linear assumption, we propose two algorithms based on conformal inference. In the first a TARGETCIT inear assumption, we propose two algorithms based on conformal inference. In the first algorithm WCCI, we revisit weighted conformal inference and introduce a new non-conformity score based on partial likelihood. We then propose a two-stage algorithm T-SCI, where we run WCCI in the first stage and apply quantile conformal inference to calibrate the results in the second stage. Theoretical analysis shows that T-SCI returns guaranteed coverage under milder assumptions than WCCI. We conduct extensive experiments on synthetic data and real data using different methods, which validate our analysis.",
    "preprocessed": [
      40,
      13,
      2552,
      7,
      3677,
      11,
      20131,
      51,
      3,
      349,
      24,
      111,
      36,
      797,
      7,
      0,
      3669,
      153,
      2,
      336,
      71,
      2138,
      2,
      78,
      2572,
      373,
      1,
      19115,
      3,
      186,
      584,
      2790,
      3643,
      3,
      731,
      43,
      1417,
      9438,
      2420,
      12,
      0,
      1252,
      1669,
      2,
      336,
      71,
      42,
      81,
      341,
      3959,
      756,
      1,
      108,
      3,
      104,
      14890,
      0,
      584,
      3643,
      11,
      903,
      548,
      10,
      1029,
      3,
      3959,
      6,
      19004,
      10,
      504339,
      9,
      9,
      3,
      24,
      9557,
      0,
      9438,
      2420,
      1,
      7,
      6614,
      0,
      9438,
      2420,
      185,
      584,
      3643,
      3,
      24,
      790,
      48,
      815,
      55,
      18,
      9813,
      4139,
      1,
      5,
      0,
      121,
      8,
      504340,
      155261,
      3643,
      3,
      24,
      790,
      48,
      815,
      55,
      18,
      9813,
      4139,
      1,
      5,
      0,
      121,
      338,
      457403,
      3,
      24,
      19229,
      3027,
      9813,
      4139,
      4,
      2317,
      8,
      97,
      132,
      6,
      18294,
      757,
      55,
      18,
      1015,
      2647,
      1,
      24,
      332,
      790,
      8,
      48,
      6,
      443,
      338,
      117,
      6,
      5520,
      3,
      349,
      24,
      2661,
      457403,
      5,
      0,
      121,
      443,
      4,
      2669,
      23998,
      9813,
      4139,
      7,
      20372,
      0,
      34,
      5,
      0,
      389,
      443,
      1,
      1361,
      64,
      875,
      15,
      117,
      6,
      5520,
      7559,
      9438,
      2420,
      186,
      15157,
      3900,
      47,
      457403,
      1,
      24,
      4631,
      1492,
      482,
      18,
      1614,
      51,
      4,
      527,
      51,
      42,
      84,
      81,
      3,
      35,
      4041,
      82,
      64,
      1
    ],
    "tc_index": 101
  },
  "2103.04556_1907.00825_1": {
    "citation_context": "Cox regression was first proposed in Cox (1972), which is a semi-parametric method focusing on estimating the hazard function. Among all its extensions, Akritas et al. (1995) first proposed using a one-hidden layer perceptron to replace the linear predictor of the coefficient. However, it generally failed mainly due to the low expressivity of the one-hidden layer perceptron (Xiang et al., 2000;Sargent, 2001). Therefore, Katzman et al. (2018) proposed to use the multi-layer perceptron instead of the one-layer perceptron (DeepSurv). Furthermore, (Kvamme et al., 2019) generalize the idea to the non-proportional hazard settings. In this paper, we unify their names as Cox-MLP when the context is clear. However, this line of work lacks a theoretical guarantee. This paper tries to fill this blank and propose the first guaranteed coverage of the survival time.",
    "ref_id": "1907.00825",
    "citing_id": "2103.04556",
    "masked_text": "Cox regression was first proposed in OTHERCIT, which is a semi-parametric method focusing on estimating the hazard function. Among all its extensions, OTHERCIT first proposed using a one-hidden layer perceptron to replace the linear predictor of the coefficient. However, it generally failed mainly due to the low expressivity of the one-hidden layer perceptron (OTHERCIT;OTHERCIT). Therefore, OTHERCIT proposed to use the multi-layer perceptron instead of the one-layer perceptron (DeepSurv). Furthermore, (OTHERCIT) generalize the idea to the n TARGETCIT coefficient. However, it generally failed mainly due to the low expressivity of the one-hidden layer perceptron (OTHERCIT;OTHERCIT). Therefore, OTHERCIT proposed to use the multi-layer perceptron instead of the one-layer perceptron (DeepSurv). Furthermore, (OTHERCIT) generalize the idea to the non-proportional hazard settings. In this paper, we unify their names as Cox-MLP when the context is clear. However, this line of work lacks a theoretical guarantee. This paper tries to fill this blank and propose the first guaranteed coverage of the survival time.",
    "preprocessed": [
      3959,
      756,
      14,
      121,
      262,
      5,
      504341,
      3,
      35,
      13,
      8,
      2548,
      6,
      4806,
      107,
      3289,
      18,
      3528,
      0,
      3118,
      145,
      1,
      154,
      63,
      78,
      6054,
      3,
      504341,
      121,
      262,
      42,
      8,
      69,
      6,
      4733,
      1003,
      19414,
      7,
      6264,
      0,
      584,
      2790,
      2,
      0,
      2074,
      1,
      108,
      3,
      40,
      1223,
      1955,
      1078,
      202,
      7,
      0,
      124,
      28095,
      2,
      0,
      69,
      6,
      4733,
      1003,
      19414,
      10,
      504339,
      9,
      1,
      418,
      3,
      504341,
      262,
      7,
      85,
      0,
      725,
      6,
      1003,
      19414,
      2138,
      2,
      0,
      69,
      6,
      1003,
      19414,
      10,
      504339,
      9,
      1,
      657,
      3,
      10,
      504341,
      9,
      10072,
      0,
      2842,
      7,
      0,
      98,
      504340,
      2074,
      1,
      108,
      3,
      40,
      1223,
      1955,
      1078,
      202,
      7,
      0,
      124,
      28095,
      2,
      0,
      69,
      6,
      4733,
      1003,
      19414,
      10,
      504339,
      9,
      1,
      418,
      3,
      504341,
      262,
      7,
      85,
      0,
      725,
      6,
      1003,
      19414,
      2138,
      2,
      0,
      69,
      6,
      1003,
      19414,
      10,
      504339,
      9,
      1,
      657,
      3,
      10,
      504341,
      9,
      10072,
      0,
      2842,
      7,
      0,
      132,
      6,
      3346,
      3118,
      2247,
      1,
      5,
      20,
      130,
      3,
      24,
      28036,
      54,
      7454,
      19,
      3959,
      6,
      19004,
      104,
      0,
      840,
      13,
      1343,
      1,
      108,
      3,
      20,
      550,
      2,
      258,
      7925,
      8,
      1361,
      6574,
      1,
      20,
      130,
      13013,
      7,
      8173,
      20,
      14299,
      4,
      790,
      0,
      121,
      9438,
      2420,
      2,
      0,
      336,
      71,
      1
    ],
    "tc_index": 101
  },
  "2103.04556_1907.00825_2": {
    "citation_context": "where \u039b 0 (t) is the baseline cumulative hazard function, and g(X i ) is the individual effect named as predictor. Remark: There are several non-proportional hazard Cox models which replace g(x i ) with g(x i , t) (e.g., Kvamme et al. (2019)). Although our proposed algorithm can be directly generalized to non-proportional settings, we only consider proportional hazard models for clarity in this paper.",
    "ref_id": "1907.00825",
    "citing_id": "2103.04556",
    "masked_text": "where \u039b 0 (t) is the baseline cumulative hazard function, and g(X i ) is the individual effect named as predictor. Remark: There are several non-proportional hazard Cox models which replace g(x i ) with g(x i , t) (e.g., OTHERCIT). Although our proposed algorithm can be directly generalized to non-proportional settings, we only consider proportional hazard models for clarity in this paper. TARGETCIT where \u039b 0 (t) is the baseline cumulative hazard function, and g(X i ) is the individual effect named as predictor. Remark: There are several non-proportional hazard Cox models which replace g(x i ) with g(x i , t) (e.g., OTHERCIT). Although our proposed algorithm can be directly generalized to non-proportional settings, we only consider proportional hazard models for clarity in this paper.",
    "preprocessed": [
      349,
      7164,
      694,
      10,
      117,
      9,
      13,
      0,
      799,
      3376,
      3118,
      145,
      3,
      4,
      45407,
      105,
      9,
      13,
      0,
      517,
      93,
      4061,
      19,
      2790,
      1,
      26281,
      29,
      103,
      22,
      225,
      132,
      6,
      3346,
      3118,
      3959,
      229,
      35,
      6264,
      45407,
      105,
      9,
      11,
      45407,
      105,
      3,
      117,
      9,
      10,
      1029,
      3,
      504341,
      9,
      1,
      259,
      82,
      262,
      338,
      43,
      26,
      990,
      2075,
      7,
      132,
      6,
      3346,
      2247,
      3,
      24,
      111,
      1324,
      3346,
      3118,
      229,
      12,
      12795,
      5,
      20,
      130,
      1,
      504340,
      349,
      7164,
      694,
      10,
      117,
      9,
      13,
      0,
      799,
      3376,
      3118,
      145,
      3,
      4,
      45407,
      105,
      9,
      13,
      0,
      517,
      93,
      4061,
      19,
      2790,
      1,
      26281,
      29,
      103,
      22,
      225,
      132,
      6,
      3346,
      3118,
      3959,
      229,
      35,
      6264,
      45407,
      105,
      9,
      11,
      45407,
      105,
      3,
      117,
      9,
      10,
      1029,
      3,
      504341,
      9,
      1,
      259,
      82,
      262,
      338,
      43,
      26,
      990,
      2075,
      7,
      132,
      6,
      3346,
      2247,
      3,
      24,
      111,
      1324,
      3346,
      3118,
      229,
      12,
      12795,
      5,
      20,
      130,
      1
    ],
    "tc_index": 79
  },
  "2103.04556_1907.00825_3": {
    "citation_context": "For the case when g(\u2022) is not linear, Lee et al. (2018) and Kvamme et al. (2019) propose Cox-MLP which uses neural networks to replace the linear predictor g(X i ). Concretely, they use the negative partial log-likelihood as the training loss, with a penalty on the complexity of g(\u2022).",
    "ref_id": "1907.00825",
    "citing_id": "2103.04556",
    "masked_text": "For the case when g(\u2022) is not linear, OTHERCIT and OTHERCIT propose Cox-MLP which uses neural networks to replace the linear predictor g(X i ). Concretely, they use the negative partial log-likelihood as the training loss, with a penalty on the complexity of g(\u2022). TARGETCIT For the case when g(\u2022) is not linear, OTHERCIT and OTHERCIT propose Cox-MLP which uses neural networks to replace the linear predictor g(X i ). Concretely, they use the negative partial log-likelihood as the training loss, with a penalty on the complexity of g(\u2022).",
    "preprocessed": [
      12,
      0,
      150,
      104,
      504339,
      9,
      13,
      30,
      584,
      3,
      504341,
      4,
      504341,
      790,
      3959,
      6,
      19004,
      35,
      1551,
      903,
      548,
      7,
      6264,
      0,
      584,
      2790,
      45407,
      105,
      9,
      1,
      42341,
      3,
      160,
      85,
      0,
      399,
      1015,
      2539,
      6,
      2647,
      19,
      0,
      639,
      401,
      3,
      11,
      8,
      11233,
      18,
      0,
      1321,
      2,
      504339,
      9,
      1,
      504340,
      12,
      0,
      150,
      104,
      504339,
      9,
      13,
      30,
      584,
      3,
      504341,
      4,
      504341,
      790,
      3959,
      6,
      19004,
      35,
      1551,
      903,
      548,
      7,
      6264,
      0,
      584,
      2790,
      45407,
      105,
      9,
      1,
      42341,
      3,
      160,
      85,
      0,
      399,
      1015,
      2539,
      6,
      2647,
      19,
      0,
      639,
      401,
      3,
      11,
      8,
      11233,
      18,
      0,
      1321,
      2,
      504339,
      9,
      1
    ],
    "tc_index": 55
  },
  "2103.04556_1907.00825_4": {
    "citation_context": "Algorithms. We choose the linear Cox regression (labeled as Cox Reg.) as a baseline. Besides, we conduct CoxPH (Katzman et al., 2018) and CoxCC (Kvamme et al., 2019) (both belong to Cox-MLP) using S(t) to return confidence band although they do not contain a theoretical guarantee.",
    "ref_id": "1907.00825",
    "citing_id": "2103.04556",
    "masked_text": "Algorithms. We choose the linear Cox regression (labeled as Cox Reg.) as a baseline. Besides, we conduct CoxPH (OTHERCIT) and CoxCC (OTHERCIT) (both belong to Cox-MLP) using S(t) to return confidence band although they do not contain a theoretical guarantee. TARGETCIT Algorithms. We choose the linear Cox regression (labeled as Cox Reg.) as a baseline. Besides, we conduct CoxPH (OTHERCIT) and CoxCC (OTHERCIT) (both belong to Cox-MLP) using S(t) to return confidence band although they do not contain a theoretical guarantee.",
    "preprocessed": [
      815,
      1,
      24,
      5433,
      0,
      584,
      3959,
      756,
      10,
      1828,
      19,
      3959,
      22698,
      1,
      9,
      19,
      8,
      799,
      1,
      3769,
      3,
      24,
      4631,
      504339,
      10,
      504341,
      9,
      4,
      504339,
      10,
      504341,
      9,
      10,
      60,
      6345,
      7,
      3959,
      6,
      19004,
      9,
      42,
      62583,
      9,
      7,
      3140,
      1252,
      1669,
      259,
      160,
      491,
      30,
      1844,
      8,
      1361,
      6574,
      1,
      504340,
      815,
      1,
      24,
      5433,
      0,
      584,
      3959,
      756,
      10,
      1828,
      19,
      3959,
      22698,
      1,
      9,
      19,
      8,
      799,
      1,
      3769,
      3,
      24,
      4631,
      504339,
      10,
      504341,
      9,
      4,
      504339,
      10,
      504341,
      9,
      10,
      60,
      6345,
      7,
      3959,
      6,
      19004,
      9,
      42,
      62583,
      9,
      7,
      3140,
      1252,
      1669,
      259,
      160,
      491,
      30,
      1844,
      8,
      1361,
      6574,
      1
    ],
    "tc_index": 56
  },
  "2103.04556_1907.00825_5": {
    "citation_context": "Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much",
    "ref_id": "1907.00825",
    "citing_id": "2103.04556",
    "masked_text": "Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much TARGETCIT Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much",
    "preprocessed": [
      461,
      18,
      3027,
      4,
      27411,
      229,
      22,
      307,
      5,
      3058,
      480,
      1,
      183,
      2,
      27411,
      229,
      22,
      701,
      504340,
      461,
      18,
      3027,
      4,
      27411,
      229,
      22,
      307,
      5,
      3058,
      480,
      1,
      183,
      2,
      27411,
      229,
      22,
      701
    ],
    "tc_index": 18
  },
  "2103.04556_1907.00825_6": {
    "citation_context": "Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much",
    "ref_id": "1907.00825",
    "citing_id": "2103.04556",
    "masked_text": "Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much TARGETCIT Comparison on weighted and unweighted models are shown in Figure 8. Performance of unweighted models are much",
    "preprocessed": [
      461,
      18,
      3027,
      4,
      27411,
      229,
      22,
      307,
      5,
      3058,
      480,
      1,
      183,
      2,
      27411,
      229,
      22,
      701,
      504340,
      461,
      18,
      3027,
      4,
      27411,
      229,
      22,
      307,
      5,
      3058,
      480,
      1,
      183,
      2,
      27411,
      229,
      22,
      701
    ],
    "tc_index": 18
  }
}